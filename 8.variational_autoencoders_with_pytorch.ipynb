{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8.variational_autoencoders_with_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNcGHHBG2yWDtmNAtiT1nLC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajay-2007/deep-learning-projects/blob/master/8.variational_autoencoders_with_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CCv2-9b-WCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scrrhg5prqgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FelEEo9isI-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a directory is not exists\n",
        "sample_dir = 'samples'\n",
        "\n",
        "if not os.path.exists(sample_dir):\n",
        "  os.makedirs(sample_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwaTih9ssWUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper-parameters\n",
        "image_size = 784\n",
        "h_dim = 400\n",
        "z_dim = 20\n",
        "num_epochs = 15\n",
        "batch_size = 128\n",
        "learning_rate = 1e-3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBz5vnuOsl6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST dataset\n",
        "\n",
        "dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                     train=True,\n",
        "                                     transform=transforms.ToTensor(),\n",
        "                                     download=True)\n",
        "\n",
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA4b4mJGs6wU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloader\n",
        "dataloader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MEMN9I0tFna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Variational Autoencoders model\n",
        "\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
        "    super(VAE, self).__init__()\n",
        "    self.fc1 = nn.Linear(image_size, h_dim)\n",
        "    self.fc2 = nn.Linear(h_dim, z_dim)\n",
        "    self.fc3 = nn.Linear(h_dim, z_dim)\n",
        "    self.fc4 = nn.Linear(z_dim, h_dim)\n",
        "    self.fc5 = nn.Linear(h_dim, image_size)\n",
        "  \n",
        "  def encode(self, x):\n",
        "    h = F.relu(self.fc1(x))\n",
        "    return self.fc2(h), self.fc3(h)\n",
        "  \n",
        "  def reparameterize(self, mu, log_var):\n",
        "    std = torch.exp(log_var/2)\n",
        "    eps = torch.rand_like(std)\n",
        "    return mu + eps * std\n",
        "  \n",
        "  def decode(self, z):\n",
        "    h = F.relu(self.fc4(z))\n",
        "    return F.sigmoid(self.fc5(h))\n",
        "  \n",
        "  def forward(self, x):\n",
        "    mu, log_var = self.encode(x)\n",
        "    z = self.reparameterize(mu, log_var)\n",
        "    x_reconst = self.decode(z)\n",
        "    return x_reconst, mu, log_var\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wccIePKJuPt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = VAE().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIaXAjNMu8B7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23de218a-eba7-4118-c2c9-19a997133a54"
      },
      "source": [
        "# Start training\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(dataloader):\n",
        "    # Forward pass\n",
        "    images = images.to(device).view(-1, image_size)\n",
        "    x_reconst, mu, log_var = model.forward(images)\n",
        "\n",
        "    # Compute reconstruction loss and kl divergence\n",
        "    reconst_loss = F.binary_cross_entropy(x_reconst, images, size_average=False)\n",
        "    kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "\n",
        "    # Backpropagation and optimize\n",
        "    loss = reconst_loss + kl_div\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%100 == 0:\n",
        "      print('Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}'.format(\n",
        "          epoch+1,\n",
        "          num_epochs,\n",
        "          i+1,\n",
        "          len(dataloader),\n",
        "          reconst_loss.item(),\n",
        "          kl_div.item() \n",
        "      ))\n",
        "\n",
        "  # performing validation\n",
        "  with torch.no_grad():\n",
        "    # Save the sampled images\n",
        "    z = torch.randn(batch_size, z_dim).to(device)\n",
        "    out = model.decode(z).view(-1, 1, 28, 28)\n",
        "    save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
        "\n",
        "    # Save the reconstructed image\n",
        "    out, _, _ = model.forward(images)\n",
        "    x_concat = torch.cat([images.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
        "    save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch[1/15], Step [100/469], Reconst Loss: 18897.0781, KL Div: 831.1255\n",
            "Epoch[1/15], Step [200/469], Reconst Loss: 15424.4229, KL Div: 944.5419\n",
            "Epoch[1/15], Step [300/469], Reconst Loss: 14033.7588, KL Div: 1069.1892\n",
            "Epoch[1/15], Step [400/469], Reconst Loss: 12817.4062, KL Div: 1115.1172\n",
            "Epoch[2/15], Step [100/469], Reconst Loss: 12242.3799, KL Div: 1199.4537\n",
            "Epoch[2/15], Step [200/469], Reconst Loss: 11103.2051, KL Div: 1134.6670\n",
            "Epoch[2/15], Step [300/469], Reconst Loss: 11413.7461, KL Div: 1212.8529\n",
            "Epoch[2/15], Step [400/469], Reconst Loss: 11482.8730, KL Div: 1205.9646\n",
            "Epoch[3/15], Step [100/469], Reconst Loss: 11572.3271, KL Div: 1235.8120\n",
            "Epoch[3/15], Step [200/469], Reconst Loss: 11105.0576, KL Div: 1230.4738\n",
            "Epoch[3/15], Step [300/469], Reconst Loss: 10754.8809, KL Div: 1253.6549\n",
            "Epoch[3/15], Step [400/469], Reconst Loss: 10684.3447, KL Div: 1220.6227\n",
            "Epoch[4/15], Step [100/469], Reconst Loss: 10405.5312, KL Div: 1237.2039\n",
            "Epoch[4/15], Step [200/469], Reconst Loss: 10559.1074, KL Div: 1285.4622\n",
            "Epoch[4/15], Step [300/469], Reconst Loss: 11014.0957, KL Div: 1248.0032\n",
            "Epoch[4/15], Step [400/469], Reconst Loss: 10400.8828, KL Div: 1285.2915\n",
            "Epoch[5/15], Step [100/469], Reconst Loss: 10379.6328, KL Div: 1226.1304\n",
            "Epoch[5/15], Step [200/469], Reconst Loss: 10732.4482, KL Div: 1256.4822\n",
            "Epoch[5/15], Step [300/469], Reconst Loss: 9868.5898, KL Div: 1275.3467\n",
            "Epoch[5/15], Step [400/469], Reconst Loss: 10137.3594, KL Div: 1250.4866\n",
            "Epoch[6/15], Step [100/469], Reconst Loss: 10011.5488, KL Div: 1277.6150\n",
            "Epoch[6/15], Step [200/469], Reconst Loss: 9976.5498, KL Div: 1207.0918\n",
            "Epoch[6/15], Step [300/469], Reconst Loss: 10191.6719, KL Div: 1296.8151\n",
            "Epoch[6/15], Step [400/469], Reconst Loss: 9796.3828, KL Div: 1229.9119\n",
            "Epoch[7/15], Step [100/469], Reconst Loss: 10072.1748, KL Div: 1291.3645\n",
            "Epoch[7/15], Step [200/469], Reconst Loss: 10240.9863, KL Div: 1296.4302\n",
            "Epoch[7/15], Step [300/469], Reconst Loss: 9770.5137, KL Div: 1329.2910\n",
            "Epoch[7/15], Step [400/469], Reconst Loss: 9802.9238, KL Div: 1246.2358\n",
            "Epoch[8/15], Step [100/469], Reconst Loss: 10283.0801, KL Div: 1300.9041\n",
            "Epoch[8/15], Step [200/469], Reconst Loss: 10289.4824, KL Div: 1306.5939\n",
            "Epoch[8/15], Step [300/469], Reconst Loss: 10188.0254, KL Div: 1335.2441\n",
            "Epoch[8/15], Step [400/469], Reconst Loss: 10249.3105, KL Div: 1254.8743\n",
            "Epoch[9/15], Step [100/469], Reconst Loss: 9977.3926, KL Div: 1282.7783\n",
            "Epoch[9/15], Step [200/469], Reconst Loss: 10116.4355, KL Div: 1268.0693\n",
            "Epoch[9/15], Step [300/469], Reconst Loss: 9755.8711, KL Div: 1278.1389\n",
            "Epoch[9/15], Step [400/469], Reconst Loss: 9847.9238, KL Div: 1258.3846\n",
            "Epoch[10/15], Step [100/469], Reconst Loss: 9816.5420, KL Div: 1302.9220\n",
            "Epoch[10/15], Step [200/469], Reconst Loss: 9633.3369, KL Div: 1261.8859\n",
            "Epoch[10/15], Step [300/469], Reconst Loss: 9950.8633, KL Div: 1312.8951\n",
            "Epoch[10/15], Step [400/469], Reconst Loss: 9415.9180, KL Div: 1259.6899\n",
            "Epoch[11/15], Step [100/469], Reconst Loss: 9649.3057, KL Div: 1271.8215\n",
            "Epoch[11/15], Step [200/469], Reconst Loss: 9943.2207, KL Div: 1310.9745\n",
            "Epoch[11/15], Step [300/469], Reconst Loss: 9518.5029, KL Div: 1313.6184\n",
            "Epoch[11/15], Step [400/469], Reconst Loss: 9485.9395, KL Div: 1267.1361\n",
            "Epoch[12/15], Step [100/469], Reconst Loss: 9994.3711, KL Div: 1278.7300\n",
            "Epoch[12/15], Step [200/469], Reconst Loss: 9805.6387, KL Div: 1269.5574\n",
            "Epoch[12/15], Step [300/469], Reconst Loss: 9512.2246, KL Div: 1280.2310\n",
            "Epoch[12/15], Step [400/469], Reconst Loss: 10132.9707, KL Div: 1302.6511\n",
            "Epoch[13/15], Step [100/469], Reconst Loss: 9335.3389, KL Div: 1248.6603\n",
            "Epoch[13/15], Step [200/469], Reconst Loss: 9730.7754, KL Div: 1262.6208\n",
            "Epoch[13/15], Step [300/469], Reconst Loss: 9662.3955, KL Div: 1294.1273\n",
            "Epoch[13/15], Step [400/469], Reconst Loss: 9545.8652, KL Div: 1317.0415\n",
            "Epoch[14/15], Step [100/469], Reconst Loss: 9597.0078, KL Div: 1295.5806\n",
            "Epoch[14/15], Step [200/469], Reconst Loss: 9326.5352, KL Div: 1280.2419\n",
            "Epoch[14/15], Step [300/469], Reconst Loss: 9919.1641, KL Div: 1317.3535\n",
            "Epoch[14/15], Step [400/469], Reconst Loss: 9667.1738, KL Div: 1269.2883\n",
            "Epoch[15/15], Step [100/469], Reconst Loss: 9491.2793, KL Div: 1285.6174\n",
            "Epoch[15/15], Step [200/469], Reconst Loss: 9529.3926, KL Div: 1244.0775\n",
            "Epoch[15/15], Step [300/469], Reconst Loss: 9827.9238, KL Div: 1282.4670\n",
            "Epoch[15/15], Step [400/469], Reconst Loss: 9792.7129, KL Div: 1260.4978\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow_data_and_deployement_part_4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXI4SKM8me6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Caching with tf.data\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "dataset = tfds.load('cats_vs_dogs', split=tfds.Split.TRAIN)\n",
        "\n",
        "# In-memory caching\n",
        "train_dataset = dataset.cache()\n",
        "model.fit(train_dataset, epochs=...)\n",
        "\n",
        "# Disk caching\n",
        "train_dataset = dataset.cache(filename='cache')\n",
        "model.fit(train_dataset, epochs=...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YttOBOkHnFYa",
        "colab_type": "text"
      },
      "source": [
        "# Parallelism with tf.data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fgPvGrKni1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment(features):\n",
        "  X = tf.image.random_flip_left_right(features['image'])\n",
        "  X = tf.image.random_flip_up_down(X)\n",
        "  X = tf.image.random_brightness(X, max_delta=0.1)\n",
        "  X = tf.image.random_saturation(X, lower=0.75, upper=1.5)\n",
        "  X = tf.image.random_hue(X, max_delta=0.15)\n",
        "  X = tf.image.random_contrast(X, lower=0.75, upper=1.5)\n",
        "  X = tf.image.resize(X, (224, 224))\n",
        "  image = X / 255.0\n",
        "\n",
        "  return image, features['label']"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlxociZPnkNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What happens when you map that transformation?\n",
        "\n",
        "dataset = tfds.load('cats_vs_dogs', split=tfds.Split.TRAIN)\n",
        "\n",
        "augmented_dataset = dataset.map(augment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPsrzcJAnkDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parallelizing data transformations\n",
        "\n",
        "augmented_dataset = dataset.map(augment, num_parallel_calls=1)\n",
        "\n",
        "# Maximizing the utilization of CPU cores\n",
        "\n",
        "# Get the number of available cpu cores\n",
        "num_cores = multiprocessing.cpu_count()\n",
        "\n",
        "# Set num_parallel_calls with 'num_cores'\n",
        "augmented_dataset = dataset.map(augment, num_parallel_calls=num_cores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-cMEYxNpOpN",
        "colab_type": "text"
      },
      "source": [
        "# Autotuning\n",
        "\n",
        "* tf.data.experimental.AUTOTUNE\n",
        "* Tunes the value dynamically at runtime\n",
        "* Decides on the level of parallelism\n",
        "* Tweaks values of parameters in transformations (tf.data)\n",
        "  * Buffer size (map, prefetch, shuffle, ...)\n",
        "  * CPU budget (num_parallel_calls)\n",
        "  * I/O (num_parallel_reads)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bYI88nepJlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Autotune in practice\n",
        "from tensorflow.data.experimental import AUTOTUNE\n",
        "\n",
        "augmented_dataset = datset.map(\n",
        "    augment,\n",
        "    num_parallel_calls=AUTOTUNE\n",
        ")\n",
        "\n",
        "# Parallelizing data loading\n",
        "\n",
        "dataset = tfds.load('cats_vs_dogs', split=tfds.Split.TRAIN)\n",
        "\n",
        "# With prefetch\n",
        "train_dataset = dataset.map(format_image).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-dG04hQqwXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parallelizing data extraction\n",
        "\n",
        "TFRECORDS_DIR = '/root/tensorflow_datasets/cats_vs_dogs/<dataset-version>/'\n",
        "files = tf.data.Dataset.list_files(TFRECORDS_DIR + \"cats_vs_dogs-train.tfrecord-*\")\n",
        "\n",
        "num_parallel_reads = 4\n",
        "\n",
        "dataset = files.interleave(\n",
        "    tf.data.TFRecordDataset, # map function\n",
        "    cycle_length=num_parallel_reads, \n",
        "    num_parallel_calls=tf.data.experimental.AUTOTUNE \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlhgkIyrrvc1",
        "colab_type": "text"
      },
      "source": [
        "# Best practices for code improvements\n",
        "\n",
        "## Performance considerations\n",
        "* The Dataset APIs are designed to be flexible\n",
        "* Most operations are commutative\n",
        "* Order transformations accordingly\n",
        "  * e.g., map, batch, shuffle, repeat, interleave, prefetch, etc.\n",
        "\n",
        "# Map and Batch\n",
        "## The map transformation has overhead in terms of\n",
        "* Scheduling\n",
        "* Executing the user-defined function\n",
        "\n",
        "# Solution : Vectorize the user-defined function\n",
        "```python\n",
        " dataset = dataset.batch(BATCH_SIZE).map(func) or\n",
        "```\n",
        "or \n",
        "\n",
        "```python\n",
        "options = tf.data.Options()\n",
        "options.experimental_optimization.map_vectorization.enabled = True\n",
        "dataset = dataset.with_options(options)\n",
        "\n",
        "```\n",
        "\n",
        "# Use map before cache when the transformation is expensive\n",
        "```python\n",
        "transformed_dataset = dataset.map(transforms_func).cache()\n",
        "```\n",
        "\n",
        "\n",
        "## Shuffle and Repeat\n",
        "\n",
        "* Shuffling the dataset before applying repeat can cause slow downs\n",
        "* shuffle.repeat for ordering guarantees\n",
        "* repeat.shuffle for better performance\n",
        "\n",
        "## Map and (Interleave / Prefetch / Shuffle)\n",
        "\n",
        "* All transformations maintain an internal buffer\n",
        "* Memory footprint is affected if map affects the size of elements\n",
        "* Generally, have order that affects the memory usage the least"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzFfc4kbrupK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
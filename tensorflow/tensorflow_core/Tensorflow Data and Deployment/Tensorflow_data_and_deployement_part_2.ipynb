{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow_data_and_deployement_part_2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWe5ZMnwEbWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEb1FbEuDO_y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7ad68c4a-1805-472d-cef8-cf104473b783"
      },
      "source": [
        "train_file_path = tf.keras.utils.get_file(\n",
        "    \"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
        "\n",
        "test_file_path = tf.keras.utils.get_file(\n",
        "    \"eval.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\")\n",
        "\n",
        "def get_dataset(file_path, **kwargs):\n",
        "  dataset = tf.data.experimental.make_csv_dataset(\n",
        "      file_path,\n",
        "      batch_size=5, # Artificially small to make examples easier to show.\n",
        "      label_name='survived',\n",
        "      na_value=\"?\",\n",
        "      num_epochs=1,\n",
        "      ignore_errors=True,\n",
        "      **kwargs\n",
        "  )\n",
        "\n",
        "  return dataset\n",
        "\n",
        "raw_train_data = get_dataset(train_file_path)\n",
        "raw_test_data = get_dataset(test_file_path)\n",
        "\n",
        "# What happes after loading the CSV file?\n",
        "def show_batch(dataset):\n",
        "  for batch, label in dataset.take(1):\n",
        "    for key, value in batch.items():\n",
        "      print(\"{:20s}: {}\".format(key, value.numpy()))\n",
        "\n",
        "show_batch(get_dataset(train_file_path))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'female' b'male' b'male' b'male' b'female']\n",
            "age                 : [34. 40.  4. 39. 28.]\n",
            "n_siblings_spouses  : [0 1 4 0 1]\n",
            "parch               : [1 4 1 0 0]\n",
            "fare                : [23.     27.9    29.125  13.     82.1708]\n",
            "class               : [b'Second' b'Third' b'Third' b'Second' b'First']\n",
            "deck                : [b'unknown' b'unknown' b'unknown' b'unknown' b'unknown']\n",
            "embark_town         : [b'Southampton' b'Southampton' b'Queenstown' b'Southampton' b'Cherbourg']\n",
            "alone               : [b'n' b'n' b'n' b'y' b'n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-zmcpWQEX8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "1f3cb5fb-3207-405c-8c46-b253ecca19ed"
      },
      "source": [
        "# Getting data from named columns\n",
        "CSV_COLUMNS = ['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n",
        "\n",
        "temp_dataset = get_dataset(train_file_path, column_names=CSV_COLUMNS)\n",
        "\n",
        "show_batch(temp_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'female' b'male' b'female' b'male' b'male']\n",
            "age                 : [52. 18. 28. 28. 16.]\n",
            "n_siblings_spouses  : [1 1 1 0 0]\n",
            "parch               : [1 1 0 0 0]\n",
            "fare                : [93.5    20.2125 24.15    7.75   10.5   ]\n",
            "class               : [b'First' b'Third' b'Third' b'Third' b'Second']\n",
            "deck                : [b'B' b'unknown' b'unknown' b'unknown' b'unknown']\n",
            "embark_town         : [b'Southampton' b'Southampton' b'Queenstown' b'Queenstown' b'Southampton']\n",
            "alone               : [b'n' b'n' b'n' b'y' b'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elcrH4aSE7Uo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0b63ef0f-943c-4639-d80f-58add771cdcb"
      },
      "source": [
        "SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', 'class', 'deck', 'alone']\n",
        "temp_dataset = get_dataset(train_file_path, select_columns=SELECT_COLUMNS)\n",
        "show_batch(temp_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age                 : [28. 23. 38.  2. 28.]\n",
            "n_siblings_spouses  : [0 1 0 1 1]\n",
            "class               : [b'Third' b'First' b'Third' b'Second' b'Third']\n",
            "deck                : [b'unknown' b'D' b'unknown' b'unknown' b'unknown']\n",
            "alone               : [b'y' b'n' b'y' b'n' b'n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK2zN7ZZFYv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extracting features\n",
        "SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', 'parch', 'fare']\n",
        "\n",
        "DEFAULTS = [0, 0.0, 0.0, 0.0, 0.0]\n",
        "\n",
        "temp_dataset = get_dataset(train_file_path,\n",
        "                           select_columns=SELECT_COLUMNS,\n",
        "                           column_defaults=DEFAULTS)\n",
        "\n",
        "# Function that will pack together all the columns:\n",
        "def pack(features, label):\n",
        "  return tf.stack(list(features.values()), axis=-1), label\n",
        "\n",
        "packed_dataset = temp_dataset.map(pack)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1LD98SBKywD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "39ac28b5-d0c6-4f85-ddb1-579a5eccf93e"
      },
      "source": [
        "# Packing numeric features\n",
        "\n",
        "NUMERIC_FEATURES = ['age', 'n_siblings_spouses', 'parch', 'fare']\n",
        "\n",
        "class PackNumericFeatures(object):\n",
        "  def __init__(self, names):\n",
        "    self.names = names\n",
        "  \n",
        "  def __call__(self, features, labels):\n",
        "    numeric_features = [features.pop(name) for name in self.names]\n",
        "    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
        "    numeric_features = tf.stack(numeric_features, axis=-1)\n",
        "    features['numeric'] = numeric_features \n",
        "\n",
        "    return features, labels\n",
        "  \n",
        "packed_train_data = raw_train_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))\n",
        "\n",
        "packed_test_data = raw_test_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))\n",
        "\n",
        "show_batch(packed_train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'male' b'male' b'male' b'male' b'male']\n",
            "class               : [b'Third' b'Second' b'Third' b'First' b'First']\n",
            "deck                : [b'unknown' b'unknown' b'unknown' b'unknown' b'unknown']\n",
            "embark_town         : [b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton']\n",
            "alone               : [b'n' b'y' b'y' b'n' b'y']\n",
            "numeric             : [[ 28.     8.     2.    69.55]\n",
            " [ 28.     0.     0.     0.  ]\n",
            " [ 42.     0.     0.     7.55]\n",
            " [ 50.     2.     0.   133.65]\n",
            " [ 56.     0.     0.    26.55]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYraCg-DN4bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import functools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2BHNMeRLlFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalizing features\n",
        "def normalize_numeric_data(data, mean, std):\n",
        "  # Center the data\n",
        "  return (data - mean) / std\n",
        "\n",
        "desc = pd.read_csv(train_file_path)[NUMERIC_FEATURES].describe()\n",
        "\n",
        "MEAN, STD = np.array(desc.T['mean']), np.array(desc.T['std'])\n",
        "\n",
        "normalizer = functools.partial(normalize_numeric_data,\n",
        "                               mean = MEAN,\n",
        "                               std = STD)\n",
        "\n",
        "numeric_columns = tf.feature_column.numeric_column(\n",
        "    'numeric',\n",
        "    normalizer_fn=normalizer,\n",
        "    shape=[len(NUMERIC_FEATURES)]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzvJR5uYMfw8",
        "colab_type": "text"
      },
      "source": [
        "# Now for the categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gFklPgbMeGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CATEGORIES = {\n",
        "    'sex': ['male', 'female'],\n",
        "    'class': ['First', 'Second', 'Third'],\n",
        "    'deck': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
        "    'embark_town': ['Cherbourg', 'Southhampton', 'Queenstown'],\n",
        "    'alone': ['y', 'n']\n",
        "}\n",
        "\n",
        "cat_feature_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "    key='class',\n",
        "    vocabulary_list=['First', 'Second', 'Third'])\n",
        "\n",
        "categorical_columns = tf.feature_column.indicator_column(cat_feature_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kscmaJc4NSzn",
        "colab_type": "text"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ei8aWL_MebF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "841c6aaa-f74e-45a1-8a0c-f0e033dfa41f"
      },
      "source": [
        "dense_features = tf.keras.layers.DenseFeatures(categorical_columns + numeric_columns)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  dense_features, \n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(packed_train_data, epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-2fafc5b808c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdense_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_columns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumeric_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m model = tf.keras.Sequential([\n\u001b[1;32m      4\u001b[0m   \u001b[0mdense_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/feature_column/dense_features_v2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, feature_columns, trainable, name, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_StateManagerImplV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/feature_column/dense_features.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, feature_columns, trainable, name, partitioner, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mexpected_column_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseColumn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/feature_column/base_feature_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, feature_columns, expected_column_type, trainable, name, partitioner, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m         name=name, trainable=trainable, **kwargs)\n\u001b[1;32m     60\u001b[0m     self._feature_columns = feature_column_v2._normalize_feature_columns(  # pylint: disable=protected-access\n\u001b[0;32m---> 61\u001b[0;31m         feature_columns)\n\u001b[0m\u001b[1;32m     62\u001b[0m     self._state_manager = feature_column_v2._StateManagerImpl(  # pylint: disable=protected-access\n\u001b[1;32m     63\u001b[0m         self, self.trainable)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\u001b[0m in \u001b[0;36m_normalize_feature_columns\u001b[0;34m(feature_columns)\u001b[0m\n\u001b[1;32m   2482\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeatureColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m       raise ValueError('Items of feature_columns must be a FeatureColumn. '\n\u001b[0;32m-> 2484\u001b[0;31m                        'Given (type {}): {}.'.format(type(column), column))\n\u001b[0m\u001b[1;32m   2485\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfeature_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2486\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature_columns must not be empty.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Items of feature_columns must be a FeatureColumn. Given (type <class 'str'>): numeric."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRun_P2wMeDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNOxEzCBMeAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
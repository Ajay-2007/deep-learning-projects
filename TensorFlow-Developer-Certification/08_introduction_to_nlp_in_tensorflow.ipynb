{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_introduction_to_nlp_in_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enLp9d4djjS5"
      },
      "source": [
        "# Introduction to NLP Fundamentals in TensorFlow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (could be sequences text or speech)\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk8PERMtjke1"
      },
      "source": [
        "## Check for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJNbu7bZjkb7",
        "outputId": "bf474fe5-7152-4dc5-c399-420dc6c85e33"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-27651651-359c-d994-4543-d41c524561b8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wucC5ilHjkZX"
      },
      "source": [
        "## Get helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ir8iiHOjkWd",
        "outputId": "63e7943b-246f-423a-85f5-b02c997b9dc5"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-29 10:11:46--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-29 10:11:47 (74.3 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUAHure0jkT8"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled as disaster or not disaster).\n",
        "\n",
        "\n",
        "See the original source here: https://www.kaggle.com/c/nlp-getting-started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFl1DJpYjkQ_",
        "outputId": "f74d9b43-8b6b-4c59-d9d7-c04a883f8604"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-29 10:11:49--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.191.128, 173.194.74.128, 173.194.192.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.191.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2021-10-29 10:11:49 (74.5 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb04jXCtsTQh"
      },
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "To visualize our text samples, we first have to read them in, one way to do so would be to use Python: https://realpython.com/read-write-files-python/\n",
        "\n",
        "But I prefer to get visual straight away.\n",
        "\n",
        "So another way to do this is to use pandas..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "GCyq31S0sTOJ",
        "outputId": "cff29222-3138-46c6-e703-f9fe3cf34a9c"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VE_B-7t0sTL9",
        "outputId": "ad37c8c4-4674-4a6f-b9eb-41754e04a141"
      },
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "B2xdSdYesTHJ",
        "outputId": "8d130412-aaf9-4662-c282-786523f55339"
      },
      "source": [
        "# What does the test dataframe look like?\n",
        "test_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh_Px6MzsTEx",
        "outputId": "77701cd4-f5cd-4fed-d0da-3e43c128227e"
      },
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVaDYgV0vAsq",
        "outputId": "d56c8c69-ee06-467e-853e-3666f38c890e"
      },
      "source": [
        "# How many total samples?\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdK5otgzsTCg",
        "outputId": "43300fda-d849-4043-fd91-14ba23567b4f"
      },
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index + 5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "#OilandGas Exploration Takes Seismic Shift in #Gabon to #Somalia http://t.co/oHHolJ9vEV via @business\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "The annihilation of Jeb Christie &amp; Kasich is less than 24 hours away..\n",
            "Please God allow me at least one more full day...\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Conditions for Paris FR at 4:00 am CEST: Current Conditions:\n",
            "Fair 68 FForecast:\n",
            "Thu - Sunny. High: 87 Low: 61\n",
            "Fri - PM Thunderstorm...\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@riverroaming 'And not too much danger please.'\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "tarmineta3: Breaking news! Unconfirmed! I just heard a loud bang nearby. in what appears to be a blast of wind from my neighbour's ass.\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK06Cog_sS_7"
      },
      "source": [
        "### Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pkL6BcysS9L"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A68fq-NsS7G"
      },
      "source": [
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1, # use 10% of training data for validation data\n",
        "                                                                            random_state=42)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2Va9WKfsS4u",
        "outputId": "2b28487c-647f-4be6-e622-f3580760f040"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aVosrVYsS2H",
        "outputId": "4b10f632-3332-4c2b-d1cd-2b3c7c43fbd2"
      },
      "source": [
        "# Check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXg4ZXrPsSzi"
      },
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "When dealing with a text problem, one of the first things you'll have to do before you can build a model is to convert your text to numbers.\n",
        "\n",
        "There are few ways to do this, namely:\n",
        "* Tokenization - direct mapping of token (a token could be a word or a character) to number\n",
        "* Embedding - create a matrix of feature vector for each token(the size of the feature vector can be defined and learned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z85lUW-tjkOW"
      },
      "source": [
        "## Text vectorization (tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Igyl6bwjkLa",
        "outputId": "ac3eb3b6-de8d-4cee-af93-a689e612b156"
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IBA_EeAjkId"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (automatically add <OOV>\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    split=\"whitespace\",\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None, # how long do you want your sequences to be\n",
        "                                    pad_to_max_tokens=False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXbB-CxF5Fdc",
        "outputId": "fe6c5fa3-6b67-4433-bf77-88d57eb736d7"
      },
      "source": [
        "len(train_sentences[0].split())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdojQG6ljkFl",
        "outputId": "adf0664a-e127-43d6-8560-5c86191765ef"
      },
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences]) / len(train_sentences))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ2clO0-5AEu"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words froma Tweet does a model see)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMz83ppL7WlB",
        "outputId": "056eaed6-c67b-4efe-b904-3c3b65da0510"
      },
      "source": [
        "max_length"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUyUjeLm5ACG"
      },
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4bJlurz4_7l",
        "outputId": "960737c6-cd16-454b-9ba0-9cde67a0c7d2"
      },
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrBffSrZ4_4Y",
        "outputId": "b3f72b79-bca7-4f68-f2e0-fb6b5075c04f"
      },
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "\\n\\n Vectorized version:\")\n",
        "\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " http://t.co/kG5pLkeDhr WRAPUP 2-U.S. cable TV companies' shares crushed after Disney disappoints http://t.co/QeIhvn3DNQ\n",
            "\n",
            " Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[   1, 3240, 4181, 1317,  755, 1697, 1594,  553,   43, 1872, 3925,\n",
              "           1,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K3PYsgH4_1Y",
        "outputId": "aca929ad-a756-4e5a-e5eb-ecea979cdb9d"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in our training data\n",
        "top_5_words = words_in_vocab[:5] # get the most common words\n",
        "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"5 most common words: {top_5_words}\")\n",
        "print(f\"5 least common words: {bottom_5_words}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djTwsLez4_sg"
      },
      "source": [
        "### Creating an Embedding using an Embedding Layer\n",
        "\n",
        "To make our embedding, we're going to use TensorFlow's embedding layer: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "\n",
        "The parameters we care most about for our embedding layer:\n",
        "* `input_dim` = the size of our vocabulary\n",
        "* `output_dim` = the size of the output embedding vector, for example, a value of 100 would mean each each token gets represented by a vector 100 long\n",
        "* `input_length` = length of the sequences being passed to the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iF_lAJg4_pM",
        "outputId": "7efd951b-d0c1-461b-b212-cc3079cbbe19"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             embeddings_initializer=\"uniform\",\n",
        "                             output_dim=128, # output shape\n",
        "                             input_length=max_length # how long is each input\n",
        "                             )\n",
        "\n",
        "embedding"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f03c035cfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osNYnlIA-ccI",
        "outputId": "4b4e6555-801c-4e6d-a98c-ebacd0a86523"
      },
      "source": [
        "# Get a random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "\\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " RT @calestous: Tanzania elephant population declined by 60% in five years census reveals http://t.co/8zy9N6fX9T http://t.co/ITZ9masBvZ\n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.04194273,  0.04956457, -0.04972999, ..., -0.03826877,\n",
              "         -0.03051198,  0.01098944],\n",
              "        [ 0.00066563,  0.00863009,  0.01531434, ..., -0.01908354,\n",
              "          0.03628296, -0.0423563 ],\n",
              "        [ 0.02921588,  0.00808756, -0.02672966, ...,  0.01646193,\n",
              "         -0.02096053,  0.02657017],\n",
              "        ...,\n",
              "        [ 0.04407749, -0.00076033,  0.01010622, ...,  0.01071454,\n",
              "          0.03882677, -0.03359213],\n",
              "        [ 0.00066563,  0.00863009,  0.01531434, ..., -0.01908354,\n",
              "          0.03628296, -0.0423563 ],\n",
              "        [ 0.00066563,  0.00863009,  0.01531434, ..., -0.01908354,\n",
              "          0.03628296, -0.0423563 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXyTYDc74_kb",
        "outputId": "e475afbe-d0b6-481a-ced9-4f7a9bc2c5b0"
      },
      "source": [
        "# Checkout a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-0.04194273,  0.04956457, -0.04972999, -0.03236411,  0.04760662,\n",
              "        -0.02410325,  0.03593384, -0.00087285,  0.03164706, -0.03908455,\n",
              "        -0.0348066 ,  0.01440151,  0.02473252, -0.00049313, -0.01128501,\n",
              "         0.04900331,  0.0431824 , -0.04127983,  0.00707434, -0.01892505,\n",
              "         0.01429054,  0.04830017, -0.01152088, -0.03723775,  0.00596622,\n",
              "         0.01204448,  0.0043877 ,  0.0399178 , -0.00949502,  0.03297356,\n",
              "        -0.00999477,  0.00527442, -0.00670496, -0.022901  ,  0.03415649,\n",
              "        -0.03399144,  0.02094601, -0.02631282,  0.00679889, -0.00384762,\n",
              "         0.02214013, -0.02793541,  0.03977918, -0.03464567, -0.02917992,\n",
              "         0.04524207,  0.03352796,  0.00022099, -0.03566743, -0.03667931,\n",
              "         0.02328081,  0.0425314 , -0.02578381,  0.02187948, -0.00641301,\n",
              "         0.01894874, -0.04050375,  0.02045674, -0.04407084, -0.00521981,\n",
              "         0.03001187,  0.04486611,  0.00528849, -0.02224997, -0.03885376,\n",
              "         0.01236981, -0.00606564, -0.02533689,  0.04525507, -0.01476806,\n",
              "        -0.01961391,  0.02797062,  0.03483129, -0.04637424,  0.01997394,\n",
              "         0.04612574,  0.0386798 ,  0.027713  , -0.00975969, -0.02055867,\n",
              "         0.02298493, -0.03515922,  0.02915649, -0.03819507,  0.03745779,\n",
              "         0.01168253,  0.00981393, -0.02029624, -0.03614844, -0.04897963,\n",
              "        -0.02129097,  0.02402605, -0.00673861,  0.03766558, -0.01413658,\n",
              "         0.03441938, -0.0233351 ,  0.01319646, -0.01779286,  0.02795339,\n",
              "        -0.00986606, -0.02450961,  0.04404402, -0.01534005, -0.04460546,\n",
              "         0.04394016,  0.03913231, -0.00405639, -0.04912156,  0.02921832,\n",
              "         0.02861411, -0.00602514,  0.00608505,  0.01103023, -0.03551372,\n",
              "         0.02741155, -0.02819531,  0.00944375,  0.02406535, -0.03386039,\n",
              "        -0.01600341, -0.00156229,  0.03561175,  0.01752534,  0.04962584,\n",
              "        -0.03826877, -0.03051198,  0.01098944], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'RT @calestous: Tanzania elephant population declined by 60% in five years census reveals http://t.co/8zy9N6fX9T http://t.co/ITZ9masBvZ')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYZz4AyzZbDY"
      },
      "source": [
        "## Modelling a text dataset (running a series of experiments)\n",
        "\n",
        "Now we've a got way to turn our text sequences into numbers, it's time to start building a series of modelling experiments.\n",
        "\n",
        "We'll start with a baseline and move on from there.\n",
        "\n",
        "* Model 0: Naive Bayes (baseline), this is from Sklearn ML map: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "* Model 2: LSTM model (RNN)\n",
        "* Model 3: GRU model (RNN)\n",
        "* Model 4: Bidirectional-LSTM model (RNN)\n",
        "* Model 5: 1D Convolutional Neural Network (CNN)\n",
        "* Model 6: TensorFlow Hub Pretrained Feature Extractor (using transfer learning for NLP)\n",
        "* Model 7: Same as model 6 with 10% of training data\n",
        "\n",
        "How are we doing to approach all of these?\n",
        "\n",
        "Use the standard steps in modelling with TensorFlow:\n",
        "\n",
        "* Create a model\n",
        "* Build a model\n",
        "* Fit a model\n",
        "* Evaluate our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x69ndg1ZZbAp"
      },
      "source": [
        "### Model 0: Getting a baseline\n",
        "\n",
        "As with all machine learning modelling experiments, it's important to create a baseline model so you've got a benchmark for future model\n",
        "\n",
        "To create our baseline, we'll use Sklearn's Multinomial Naive Bayes using the TF-IDF formula to convert our words to numbers.\n",
        "\n",
        "> **Note:** It's common practice to use non-DL algorithms as a baseline because of their speed and then later using DL to see if you can improve upon them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3XUOimQZa-e",
        "outputId": "ca847573-458d-4ad4-cc77-7218e8e28138"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline \n",
        "\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "  (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "  (\"clf\", MultinomialNB()), # model the text                    \n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzHu5NjAZa8C",
        "outputId": "256736d6-74ad-4ea4-ea2f-eea0d4afadaf"
      },
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gAocLdCZa59",
        "outputId": "534e7d40-4b7b-4a1e-d28a-222c13efc384"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABDr5fAgZa3b"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "We could evaluate all of our model's predictions with different metrics every time, however, this will be combersome and easily be fixed with a function\n",
        "\n",
        "Let's create one to compare our model's predictions with the truth labels using the following \n",
        "\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n",
        "\n",
        "For a deep overview of many different evaluation methods, see the Sklearn documentation: https://scikit-learn.org/stable/modules/model_evaluation.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEzlkB8sZa02"
      },
      "source": [
        "# Functio to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1-score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                   \"precision\": model_precision,\n",
        "                   \"recall\": model_recall,\n",
        "                   \"f1\": model_f1}\n",
        "\n",
        "  return model_results                   "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfaKt-YfZawz",
        "outputId": "6079be04-41a3-4c51-a742-2cde5878c164"
      },
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "\n",
        "baseline_results"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgCMctrXZauk"
      },
      "source": [
        "### Model 1: A Simple dense model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9qPjiXEZasF"
      },
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ1Uz-Kth0Fx"
      },
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numberized inputs\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token to one vector\n",
        "# x = layers.GlobalMax1D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # Create the output layer, want binary outputs so use use sigmoid activation function\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2xhI9E2h0Az",
        "outputId": "d04cd298-e058-408a-d193-96b89315b663"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0XJb94Hhz-S"
      },
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWa56zD7hz74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d57ff3-363a-449f-e682-8c0b9ba35eca"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"model_1_dense\")])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20211029-101157\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 10ms/step - loss: 0.6134 - accuracy: 0.6906 - val_loss: 0.5361 - val_accuracy: 0.7520\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.4428 - accuracy: 0.8183 - val_loss: 0.4704 - val_accuracy: 0.7887\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.3472 - accuracy: 0.8594 - val_loss: 0.4569 - val_accuracy: 0.7900\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.2850 - accuracy: 0.8905 - val_loss: 0.4657 - val_accuracy: 0.7940\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.2386 - accuracy: 0.9105 - val_loss: 0.4759 - val_accuracy: 0.7861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdiDxyjPhz5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ed8dfa-4bf2-4edf-d3a4-136424afcfde"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOiMs0c7yy8i",
        "outputId": "867b1a90-3a7a-4108-cb82-d9cdbd1a1845"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 5ms/step - loss: 0.4759 - accuracy: 0.7861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4759269058704376, 0.7860892415046692]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hAj98qkhz2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b013ce9-e994-4329-f38b-08d432625cc5"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4759269058704376, 0.7860892415046692]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSGAH5dThz0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd8ff397-e07b-45b8-c1f9-dff6d0a853d5"
      },
      "source": [
        "# Make some predictions and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgTPKKL0hzyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c866ad-9c22-48af-dea0-2f465ea9d53a"
      },
      "source": [
        "# look at a single prediction\n",
        "model_1_pred_probs[0]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.41907346], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLcbCHVhhzvY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf7d383-55d2-4ef4-f6eb-ed3465ff2145"
      },
      "source": [
        "model_1_pred_probs[:10]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.41907346],\n",
              "       [0.7157675 ],\n",
              "       [0.9980393 ],\n",
              "       [0.16113192],\n",
              "       [0.13441314],\n",
              "       [0.95370823],\n",
              "       [0.9244029 ],\n",
              "       [0.9920813 ],\n",
              "       [0.9711019 ],\n",
              "       [0.33809286]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTYxCliehztF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a6ca09-fa9e-4b9f-91b8-c7efd67b8ab5"
      },
      "source": [
        "# Convert model prediction probability to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:20]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwrfPiT1hzq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d904ebc-69c2-4088-9f89-e01c604a0acd"
      },
      "source": [
        "# Calculate our model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "\n",
        "model_1_results"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.60892388451444,\n",
              " 'f1': 0.7837076401553273,\n",
              " 'precision': 0.7892068285860523,\n",
              " 'recall': 0.7860892388451444}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eLZlmOlz6nw",
        "outputId": "cab9bcff-0c9f-4591-c8bf-f2c7717e7516"
      },
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM_fRgqwz6lz"
      },
      "source": [
        "## Visualizing learned embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBH2l8CGz6hz",
        "outputId": "ea7fc3dc-a8b7-431d-e005-04e52ad8f617"
      },
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFBXK2dM04uF",
        "outputId": "d4d028e6-7b55-4f9d-f681-46407bc9d7f6"
      },
      "source": [
        "max_vocab_length"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adrq8nSpz6fX",
        "outputId": "1639081b-a662-4f0f-b403-153d0783f114"
      },
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U6jraJQz6ck"
      },
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "# (thse are the numerical representations of each token in our training data, which have been learned for ~5 epochs)\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aib9VcDdz6YJ",
        "outputId": "825eb78b-6a2e-49d1-d30d-f95c544c75c3"
      },
      "source": [
        "print(embed_weights)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.0391174   0.05964467  0.01859065 ... -0.02277126 -0.01062814\n",
            "   0.04625481]\n",
            " [-0.00011455  0.01024415  0.01448169 ... -0.01914067  0.03488431\n",
            "  -0.04162553]\n",
            " [ 0.00599559  0.01219319 -0.0053092  ... -0.00979946  0.02415079\n",
            "   0.05339534]\n",
            " ...\n",
            " [ 0.01264802  0.03898102 -0.00624945 ... -0.04938055  0.01610429\n",
            "  -0.02969301]\n",
            " [-0.05478465  0.08381789  0.00315656 ...  0.01085234 -0.04014601\n",
            "   0.06812771]\n",
            " [-0.05594342  0.07211927  0.0716468  ... -0.09478862 -0.01786367\n",
            "   0.05503201]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR_PrDEyz6VT",
        "outputId": "6f46a4cd-e4c3-455c-fced-35b3c9921346"
      },
      "source": [
        "print(embed_weights.shape) # smae size as vocab size and embedding_dim (output_dim of our embedding layer)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HLzmhpz2MSs"
      },
      "source": [
        "Now we've got the embedding matrix our model has learned to represent our tokens, let's see how we can visualize it.\n",
        "\n",
        "To do so, TensorFlow has a handy tool called projector: https://projector.tensorflow.org/\n",
        "\n",
        "And TensorFlow has an increadible guide on word embeddings themselves: https://www.tensorflow.org/text/guide/word_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxGvI29Gz6Sh"
      },
      "source": [
        "# Creat embedding files (we got this from TensorFlow's word embeddings documentation)\n",
        "import io\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gGJ7YmpEz6Py",
        "outputId": "9e63055a-0ec9-4310-9648-87bba69b9601"
      },
      "source": [
        "# Download files from  Colab to upload to projector\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  # files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_394cec86-8a0d-48f5-b99d-d6eb1f6ff030\", \"vectors.tsv\", 15365923)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFS-DIgbz6NJ"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "RNN's are useful for sequence data.\n",
        "\n",
        "The premise of a recurrent neural network is to use the representation of a previous input to aid the representation of a later input.\n",
        "\n",
        "**Resources:** If you want an overview of the internals of a recurrent neural network, see the following:\n",
        "* MIT's sequence modelling lecture: (https://www.youtube.com/watch?v=5tvmMX8r_OM&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&index=2)\n",
        "* Chris Olah's intro to LSTMs: https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "* Andrej Karpathy's the unreasonable effectiveness of recurrent neural networks: http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrr4VoHHSNDA",
        "outputId": "b2c5b540-4a54-4444-9703-a4a695d239eb"
      },
      "source": [
        "train_sentences[:10]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "       '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "       'destroy the free fandom honestly',\n",
              "       'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "       '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "       'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbAaVGcqUmJJ"
      },
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "LSTM = long short term memory (one of the most popular LSTM cells)\n",
        "\n",
        "Our structure of an RNN typically looks like this:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers (RNNs/dense)\n",
        "-> Output (label probability)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS3APM5UhzoT"
      },
      "source": [
        "# Create an LSTM model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# print(x.shape)\n",
        "# x = layers.LSTM(units=64, return_sequences=True)(x) # when you're stacking RNN cells together, you need to set return_sequences=True\n",
        "# print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "# print(x.shape)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "# print(x.shape)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Unc7BQahzlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0628217a-4da6-4a53-8d04-75f10b83b8fc"
      },
      "source": [
        "# Get a summary\n",
        "model_2.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,333,633\n",
            "Trainable params: 1,333,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb8eJxaUYoyy"
      },
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeYIX2cxYoxJ",
        "outputId": "de8cea13-998d-4bb2-b9ee-7b9180cfb873"
      },
      "source": [
        "# Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_2_LSTM\")])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20211029-101212\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 16ms/step - loss: 0.2193 - accuracy: 0.9218 - val_loss: 0.5978 - val_accuracy: 0.7822\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1566 - accuracy: 0.9404 - val_loss: 0.6795 - val_accuracy: 0.7795\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.1276 - accuracy: 0.9518 - val_loss: 0.6099 - val_accuracy: 0.7822\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.1048 - accuracy: 0.9597 - val_loss: 0.9264 - val_accuracy: 0.7717\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0853 - accuracy: 0.9654 - val_loss: 0.9857 - val_accuracy: 0.7795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5NIYsx_YouU",
        "outputId": "cfa50421-b8f2-4dfd-8c47-952f889590e0"
      },
      "source": [
        "# Make predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.4494890e-02],\n",
              "       [4.9834052e-01],\n",
              "       [9.9998426e-01],\n",
              "       [4.5698356e-02],\n",
              "       [1.1811614e-04],\n",
              "       [9.9981850e-01],\n",
              "       [9.2875510e-01],\n",
              "       [9.9999511e-01],\n",
              "       [9.9998212e-01],\n",
              "       [3.7091625e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "covD_OlmYosO",
        "outputId": "da7b7191-c3da-466a-a24f-c04c6baaf0bc"
      },
      "source": [
        "# Convert model 2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdPe_WBoYopu",
        "outputId": "94433b27-b5fb-406a-dec9-3479fbc9b56d"
      },
      "source": [
        "# Calculate model 2 results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "\n",
        "model_2_results"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.95275590551181,\n",
              " 'f1': 0.7759572947489844,\n",
              " 'precision': 0.7854389051990907,\n",
              " 'recall': 0.7795275590551181}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYb_Xw1vYomu",
        "outputId": "02f359f7-825d-408b-dc83-db7766bc30e2"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsySjoyuYojV"
      },
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEOB-046Yof-"
      },
      "source": [
        "# Build an RNN using the GRU cell\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.GRU(64, return_sequences=True)(x) # if you want to stack recurrent layers on top of each other, you need return_sequences=True\n",
        "# print(x.shape)\n",
        "# x = layers.LSTM(42, return_sequences=True)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.GRU(99)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "# x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lliftpphzjB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07d812fd-eb73-4d3f-953d-6a0f9f1a45c4"
      },
      "source": [
        "# Get a summary\n",
        "model_3.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS5S-9ERZapq"
      },
      "source": [
        "# Compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTDFPWISZam_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694f3f14-b644-40fa-cb0a-35d739f8cb9b"
      },
      "source": [
        "# Fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                    experiment_name=\"model_3_GRU\")])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20211029-101230\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 15ms/step - loss: 0.1562 - accuracy: 0.9406 - val_loss: 0.8950 - val_accuracy: 0.7743\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0848 - accuracy: 0.9676 - val_loss: 0.8354 - val_accuracy: 0.7730\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0743 - accuracy: 0.9715 - val_loss: 0.9691 - val_accuracy: 0.7703\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0611 - accuracy: 0.9761 - val_loss: 0.9837 - val_accuracy: 0.7730\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0518 - accuracy: 0.9778 - val_loss: 1.2511 - val_accuracy: 0.7743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIntxzLIZakU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c319c923-c3a0-427e-a2b0-c2f0982b698c"
      },
      "source": [
        "# Make some predictions with our GRU model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.7157143e-03],\n",
              "       [7.7637297e-01],\n",
              "       [9.9994314e-01],\n",
              "       [5.3066306e-02],\n",
              "       [8.0615173e-05],\n",
              "       [9.9988210e-01],\n",
              "       [9.8217839e-01],\n",
              "       [9.9997604e-01],\n",
              "       [9.9994731e-01],\n",
              "       [9.3468654e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOEk-nmg1ju7",
        "outputId": "1a7c34a3-a4b8-4050-84d6-bd0357e6a198"
      },
      "source": [
        "# Convert model 3 pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PiEn2e01rEm",
        "outputId": "be04a366-dc60-4dd5-db7a-7ccc41212d60"
      },
      "source": [
        "# Calculate model 3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "\n",
        "model_3_results"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.42782152230971,\n",
              " 'f1': 0.7723566516531356,\n",
              " 'precision': 0.7757380419380466,\n",
              " 'recall': 0.7742782152230971}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S05DaQC62eg4"
      },
      "source": [
        "### Model 4: Bidirectional RNN\n",
        "\n",
        "Normal RNN's go from left to right (just like you'd read an English sentence) however, a bidirectional RNN goes from right to left as well as left to right.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0lhhXAV2ea7",
        "outputId": "8b68d9b4-9ce5-42bd-cb2c-12776d1b0413"
      },
      "source": [
        "# Build a bidirectional RNN in TensorFlow\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "# print(x.shape)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "print(x.shape)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pXT6IM22eVR",
        "outputId": "6133bcad-b3bc-49c4-bd72-2618132eefcd"
      },
      "source": [
        "# Get a summary\n",
        "model_4.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSVV7NR82eTR"
      },
      "source": [
        "# Compile model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFZ3UHkQ2eRb",
        "outputId": "4523ece1-21f3-40c8-d18b-128e62efdf30"
      },
      "source": [
        "# Fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_4_bidirectional\")])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20211029-101255\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 22ms/step - loss: 0.1044 - accuracy: 0.9707 - val_loss: 1.0129 - val_accuracy: 0.7638\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0550 - accuracy: 0.9755 - val_loss: 1.2235 - val_accuracy: 0.7625\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0489 - accuracy: 0.9784 - val_loss: 1.3176 - val_accuracy: 0.7756\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0439 - accuracy: 0.9794 - val_loss: 1.4067 - val_accuracy: 0.7651\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0410 - accuracy: 0.9791 - val_loss: 1.4842 - val_accuracy: 0.7664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVCPVPH12eNz",
        "outputId": "ccfaa505-fea7-449c-e635-b3e3022ba615"
      },
      "source": [
        "# Make predictions with our bidirectional model\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.9788001e-04],\n",
              "       [9.0254843e-01],\n",
              "       [9.9997234e-01],\n",
              "       [1.8042053e-01],\n",
              "       [1.9834633e-05],\n",
              "       [9.9967504e-01],\n",
              "       [5.6016433e-01],\n",
              "       [9.9998796e-01],\n",
              "       [9.9997675e-01],\n",
              "       [9.9882168e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTC3ZCoY7Bcs",
        "outputId": "1bfaf388-bdc0-4733-bf5e-1bd2249d7fa5"
      },
      "source": [
        "# Convert pred probs to pred labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jidu30py7Ba1",
        "outputId": "aa4548bc-1a48-4fae-de60-a4748e31d19a"
      },
      "source": [
        "# Calculate the results of our bidirectional model\n",
        "model_4_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.64041994750657,\n",
              " 'f1': 0.764784113056577,\n",
              " 'precision': 0.7670590562420062,\n",
              " 'recall': 0.7664041994750657}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76Vqj7y87BXN",
        "outputId": "c86e0272-45d1-4b3f-844f-a0486719fd82"
      },
      "source": [
        "model_3_results"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.42782152230971,\n",
              " 'f1': 0.7723566516531356,\n",
              " 'precision': 0.7757380419380466,\n",
              " 'recall': 0.7742782152230971}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wReFdDUW7BUh"
      },
      "source": [
        "## Convolutional Neural Networks for Text (and other types of sequences)\n",
        "\n",
        "We've used CNNs for images but images are typically 2D (height x width)... however, our text data is 1D.\n",
        "\n",
        "Previously we've used Conv2D for our image data but now we're going to use Conv1D.\n",
        "\n",
        "The typical structure of a Conv1D model for sequences (in our case, text):\n",
        "\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layer(s) (typically Conv1D + Pooling) -> Outputs (class probabilities)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIO_fw_j7BR-"
      },
      "source": [
        "### Model 5: Conv1D\n",
        "\n",
        "For different explantions of parameters see:\n",
        "* https://poloclub.github.io/cnn-explainer/ (this is for 2D but can relate to 1D data)\n",
        "* Difference between \"same\" and \"valid\" padding: https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flGDJKE78eZk",
        "outputId": "55f976f8-8d58-4c1b-a43b-d5832424317c"
      },
      "source": [
        "# Test out our embedding layer, Conv1D layer and max pooling\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "embedding_test = embedding(text_vectorizer([\"this is a text sentence\"])) # turn target sequence into embedding\n",
        "conv_1d = layers.Conv1D(filters=64,\n",
        "                        kernel_size=5, # this is also referred to as an ngram of 5 (meaning it looks at 5 words at a time)\n",
        "                        strides=1, # default\n",
        "                        activation=\"relu\",\n",
        "                        padding=\"same\") # default = \"valid\", the output is smaller than the input shape, \"same\" means output is same as the input\n",
        "\n",
        "conv_1d_output = conv_1d(embedding_test) # pass test embedding through conv1d layer\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output) # equivalent to \"get the most important feature\" or \"get the feature with the highest value\"\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 15, 64]), TensorShape([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2zFc9HF8eWf"
      },
      "source": [
        "# embedding_test"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW0sFs-M8eUA"
      },
      "source": [
        "# conv_1d_output"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lw3sUs88eSM"
      },
      "source": [
        "# max_pool_output"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4yfamrwqcIv",
        "outputId": "0be020db-8c80-42dc-d1dc-98b4a15392d4"
      },
      "source": [
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=5, strides=1, activation=\"relu\", padding=\"valid\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "\n",
        "# Compile Conv1D\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary of our Conv1D model\n",
        "model_5.summary()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 11, 64)            41024     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA92DQwCrQ_C",
        "outputId": "295e4a29-8e8b-47b7-b693-85c7c2fb14ca"
      },
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"Conv1D\")])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20211029-101344\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 11ms/step - loss: 0.1257 - accuracy: 0.9587 - val_loss: 0.8955 - val_accuracy: 0.7677\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.0761 - accuracy: 0.9723 - val_loss: 1.0347 - val_accuracy: 0.7612\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0600 - accuracy: 0.9771 - val_loss: 1.1398 - val_accuracy: 0.7533\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0537 - accuracy: 0.9783 - val_loss: 1.2258 - val_accuracy: 0.7572\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0499 - accuracy: 0.9780 - val_loss: 1.2347 - val_accuracy: 0.7507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9SAr3jtr7Ft",
        "outputId": "c39de1f2-2226-457c-c066-fc8da0125832"
      },
      "source": [
        "# Make some predictions with our Conv1D model\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.63365936e-01],\n",
              "       [9.71738458e-01],\n",
              "       [9.99988675e-01],\n",
              "       [5.22199422e-02],\n",
              "       [1.09059094e-07],\n",
              "       [9.99710143e-01],\n",
              "       [9.93519604e-01],\n",
              "       [9.99997377e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.68318582e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U51U95XsBO_",
        "outputId": "305f6f20-b2a0-4d92-a3f0-ee9ab286f5f7"
      },
      "source": [
        "# Convert model 5 pred probs to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xylks2GrsBL5",
        "outputId": "5efbbacf-6c00-4e95-a745-619fa1842a4d"
      },
      "source": [
        "# Evaluate model 5 predictions\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.06561679790026,\n",
              " 'f1': 0.7500861597764454,\n",
              " 'precision': 0.7501834475789994,\n",
              " 'recall': 0.7506561679790026}"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBujBi40sBKX",
        "outputId": "f1e2e5ab-c1ce-475e-a0c8-021256238d86"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cktQYBVTsBHd"
      },
      "source": [
        "## Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "Now we've built a few of our own models, let's try and use transfer learning for NLP, specifically using TensorFlow Hub's Universal Sentence Encoder: https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "\n",
        "See how the USE was created here: https://arxiv.org/abs/1803.11175"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GEVtrwJrP86B",
        "outputId": "b7bbb92a-2cef-422b-b6a4-f49f836e5672"
      },
      "source": [
        "sample_sentence"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"There's a flood in my street!\""
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd1fOZ_HsfmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "208aa270-7e8b-4a83-eec4-3eec9536d5df"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([sample_sentence,\n",
        "                       \"When you call the universal sentence encoder on a sentence, it turns it into numbers\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157024  0.0248591   0.0287805  -0.01271502  0.03971543  0.08827759\n",
            "  0.02680986  0.05589837 -0.01068731 -0.0059729   0.00639324 -0.01819523\n",
            "  0.00030817  0.09105891  0.05874644 -0.03180627  0.01512476 -0.05162928\n",
            "  0.00991369 -0.06865346 -0.04209306  0.0267898   0.03011008  0.00321069\n",
            " -0.00337969 -0.04787359  0.02266718 -0.00985924 -0.04063614 -0.01292095\n",
            " -0.04666384  0.056303   -0.03949255  0.00517685  0.02495828 -0.07014439\n",
            "  0.02871508  0.04947682 -0.00633971 -0.08960191  0.02807117 -0.00808362\n",
            " -0.01360601  0.05998649 -0.10361786 -0.05195372  0.00232955 -0.02332528\n",
            " -0.03758105  0.0332773 ], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Dht89Lsfjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3281d9-4a17-4581-80ee-7552f0775d20"
      },
      "source": [
        "embed_samples[0].shape"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz_hZKpdsfgm"
      },
      "source": [
        "# Create a Keras Layer using the USE pretrained layer from tensorflow hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[],\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name=\"USE\")"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A91hc7NsfeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0409aae6-1524-4922-913c-cf6b8fb8fcd1"
      },
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer,\n",
        "  # layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")                               \n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_6.summary()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 256,798,337\n",
            "Trainable params: 513\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTSGcNSGsfbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5198476a-bf4d-47a6-96d2-f040b21cd2e1"
      },
      "source": [
        "# Train a classifier on top of USE pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20211029-101429\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 32ms/step - loss: 0.6478 - accuracy: 0.7434 - val_loss: 0.6117 - val_accuracy: 0.7717\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.5804 - accuracy: 0.7892 - val_loss: 0.5624 - val_accuracy: 0.7769\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.5374 - accuracy: 0.7964 - val_loss: 0.5307 - val_accuracy: 0.7835\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.5090 - accuracy: 0.8015 - val_loss: 0.5095 - val_accuracy: 0.7861\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.4891 - accuracy: 0.8022 - val_loss: 0.4956 - val_accuracy: 0.7900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6FLX_TDsBEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "957abfb9-e2fd-4b15-ceac-4d53ac468d76"
      },
      "source": [
        "# Make predictions with USE TF Hub Model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.37480786],\n",
              "       [0.6838654 ],\n",
              "       [0.865154  ],\n",
              "       [0.32765767],\n",
              "       [0.65585953],\n",
              "       [0.74315155],\n",
              "       [0.82040703],\n",
              "       [0.8516634 ],\n",
              "       [0.7541844 ],\n",
              "       [0.19225344]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjkj5vdNsBCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e7f5131-9264-4a80-e414-40c4260101bd"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYvHTsJXsA_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b41ebc8a-8043-47cd-9c7a-14beac87aa31"
      },
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.00262467191601,\n",
              " 'f1': 0.7886741430048517,\n",
              " 'precision': 0.7909267110841915,\n",
              " 'recall': 0.7900262467191601}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KPpKR21sA81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faee0ccd-1dd4-44ba-a91c-a9055c6afc28"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jaB-I8hS8Jf",
        "outputId": "2514b6fd-64fb-4f36-fb0c-86a1ed5d530e"
      },
      "source": [
        "# Create model using the Sequential API\n",
        "model_7 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer,\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")                               \n",
        "], name=\"model_7_USE\")\n",
        "\n",
        "# Compile\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_7.summary()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ-qFDjoTEZ0",
        "outputId": "7ae8d208-a65b-43ef-ab62-b7be042286f1"
      },
      "source": [
        "# Train a classifier on top of USE pretrained embeddings\n",
        "model_7_history = model_7.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20211029-101514\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 27ms/step - loss: 0.5043 - accuracy: 0.7789 - val_loss: 0.4466 - val_accuracy: 0.8045\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.4137 - accuracy: 0.8162 - val_loss: 0.4384 - val_accuracy: 0.8123\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.4004 - accuracy: 0.8246 - val_loss: 0.4360 - val_accuracy: 0.8097\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.3924 - accuracy: 0.8257 - val_loss: 0.4283 - val_accuracy: 0.8136\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.3848 - accuracy: 0.8308 - val_loss: 0.4276 - val_accuracy: 0.8163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd4nBvWvUR4e",
        "outputId": "fefb23a5-6add-41b3-971b-6b69a18c96c5"
      },
      "source": [
        "# Make predictions with USE TF Hub Model\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.16715802],\n",
              "       [0.7646153 ],\n",
              "       [0.988934  ],\n",
              "       [0.20345955],\n",
              "       [0.6906989 ],\n",
              "       [0.72892064],\n",
              "       [0.9829574 ],\n",
              "       [0.9786734 ],\n",
              "       [0.94715744],\n",
              "       [0.0852498 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNDPCv56UH4X",
        "outputId": "42b1e2d8-d656-4308-f8db-f3c17ebe8ad3"
      },
      "source": [
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExxXEdcmTEXT",
        "outputId": "d0c92ad3-e575-4a34-8a43-29132376bfdb"
      },
      "source": [
        "model_7_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_7_preds)\n",
        "model_7_results"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.62729658792651,\n",
              " 'f1': 0.8149048737121865,\n",
              " 'precision': 0.8181574920275534,\n",
              " 'recall': 0.8162729658792651}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4lcWgvxTEU5",
        "outputId": "b838f1ae-4418-470a-b78d-789b21ff1d87"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4OBAlRiTESY",
        "outputId": "8f1dad47-6872-47a2-bf5c-a6e9ae67275a"
      },
      "source": [
        "len(train_sentences)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6851"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoYl3y30WiA1",
        "outputId": "008d203d-d93d-4c69-c46c-b1150beb8105"
      },
      "source": [
        "len(train_df_shuffled)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7613"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4VgfFPzWh8F"
      },
      "source": [
        "## Model 7: TF Hub Pretrained USE but with 10% of training data\n",
        "\n",
        "Transfer learning really helps when you don't have a large dataset.\n",
        "\n",
        "To see how our model performs on a smaller dataset, let's replicate `model_6` except we'll train it on 10% of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC2EBDLjmr32",
        "outputId": "b4d2e50e-df04-4ee1-b44d-a277a4ae7989"
      },
      "source": [
        "train_sentences[:5], val_sentences[:5]"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "       dtype=object),\n",
              " array(['DFR EP016 Monthly Meltdown - On Dnbheaven 2015.08.06 http://t.co/EjKRf8N8A8 #Drum and Bass #heavy #nasty http://t.co/SPHWE6wFI5',\n",
              "        'FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/qZQc8WWwcN via @usatoday',\n",
              "        'Gunmen kill four in El Salvador bus attack: Suspected Salvadoran gang members killed four people and wounded s... http://t.co/CNtwB6ScZj',\n",
              "        '@camilacabello97 Internally and externally screaming',\n",
              "        'Radiation emergency #preparedness starts with knowing to: get inside stay inside and stay tuned http://t.co/RFFPqBAz2F via @CDCgov'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0Fpd9eYWh6h",
        "outputId": "85caa71c-94cc-4348-ca85-f12d0dabae7f"
      },
      "source": [
        "# ## NOTE: Making data splits like below leads to data leakage (model_7 trained on 10% data, outperforms model_6 trained on 100% data)\n",
        "# ## Do NOT MAKE DATA SPLITS WHICH LEAK DATA FROM VALIDATION/TEST SETS INTO TRAINING SET.\n",
        "\n",
        "# # Create subsets of 10% of the training data\n",
        "\n",
        "# train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
        "# # train_10_percent.head(), len(train_10_percent)\n",
        "# train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
        "# len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(761, 761)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2LaW3gqs5U1"
      },
      "source": [
        "> **Note:** Be *very* careful when creating training/val/test splits that you don't leak data across the datasets, otherwise your model evaluation metrics will be wrong. If something looks too good to be true (a model trainedon 10% of data outperforming the same model trained on 100% of data) trust your gut and go back through to find where the error may lie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8CitRDsp8D1"
      },
      "source": [
        "# Making a better dataset split (no data leakage)\n",
        "train_10_percent_split = int(0.1 * len(train_sentences))\n",
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc-AlBt6qXPe",
        "outputId": "af6547ad-da34-4973-efde-7de3aeb56d14"
      },
      "source": [
        "np.array(train_labels_10_percent).tolist().count(1)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "279"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zs6iTzPqXNy",
        "outputId": "7f2ea31b-7140-4308-c51a-4d0d44abc6ff"
      },
      "source": [
        "np.array(train_labels_10_percent).tolist().count(0)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "406"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrpfPtaKqXL9",
        "outputId": "eaaa7fe4-e0cf-4337-99c4-17a4fd7769eb"
      },
      "source": [
        "# Check the number of targets in our subset of data\n",
        "train_df_shuffled[\"target\"].value_counts()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKnBnGySqXKE",
        "outputId": "44a9c0b6-99b2-4826-8520-99d74853f21f"
      },
      "source": [
        "pd.Series(np.array(train_labels_10_percent)).value_counts()"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpY7WJdXqXHz",
        "outputId": "2efe42d7-b455-45a1-9964-6e19860ab6a8"
      },
      "source": [
        "# Fit the model to the 10% training data subsets\n",
        "model_7_history = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder_10_percent_correct_split\")])"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent_correct_split/20211029-105612\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 87ms/step - loss: 0.6410 - accuracy: 0.7547 - val_loss: 0.6297 - val_accuracy: 0.7900\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 49ms/step - loss: 0.6305 - accuracy: 0.7781 - val_loss: 0.6225 - val_accuracy: 0.7953\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.6203 - accuracy: 0.7912 - val_loss: 0.6159 - val_accuracy: 0.7927\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 1s 49ms/step - loss: 0.6108 - accuracy: 0.7985 - val_loss: 0.6096 - val_accuracy: 0.7900\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 51ms/step - loss: 0.6017 - accuracy: 0.8029 - val_loss: 0.6041 - val_accuracy: 0.7874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFwQgaEWqXFE",
        "outputId": "fcd6d3de-52c3-4fa9-aca5-3aa70d37ecb0"
      },
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.44103968],\n",
              "       [0.5148145 ],\n",
              "       [0.652778  ],\n",
              "       [0.42705327],\n",
              "       [0.52512753],\n",
              "       [0.57101905],\n",
              "       [0.59499145],\n",
              "       [0.6046918 ],\n",
              "       [0.5754433 ],\n",
              "       [0.36795497]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAXmZEUvqW_p",
        "outputId": "3cdfc952-206a-4389-f752-bcd7e775da83"
      },
      "source": [
        "# Turn pred probs into labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxUd-yA3smch",
        "outputId": "c5ed288b-684d-412a-c833-4cc33e97ad9f"
      },
      "source": [
        "# Evaluate model 7 predictions\n",
        "model_7_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_7_preds)\n",
        "model_7_results"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.74015748031496,\n",
              " 'f1': 0.7846966492209201,\n",
              " 'precision': 0.7914920592553047,\n",
              " 'recall': 0.7874015748031497}"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ECDHJWdsmXQ",
        "outputId": "96303ba0-0842-4d1a-9f3e-d43c9735b941"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIPIhowMslwK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi6T3Ix3slti"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xujjj5vLqW89"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX3LiknUWh46",
        "outputId": "f2b6e667-2f9e-495d-deed-0873e71487e3"
      },
      "source": [
        "T# Check the number of target in our subset of data\n",
        "train_10_percent[\"target\"].value_counts()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    413\n",
              "1    348\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfKfWmmYWh3M",
        "outputId": "13fffddc-29d2-4bbf-e14b-e6f0af25b89d"
      },
      "source": [
        "train_df_shuffled[\"target\"].value_counts()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT82mj8eYqRY"
      },
      "source": [
        "To recreate a model the same as a previous model you've created you can use the `tf.keras.models.close_model()` method, see more here: https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dznCFRUJWh0O",
        "outputId": "ac227bdd-799f-4714-80b8-e4d33368d283"
      },
      "source": [
        "# Let's build the model the same as model_6\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# Compile model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary (will be same as model_6)\n",
        "model_7.summary()\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 256,798,337\n",
            "Trainable params: 513\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWVew_UTWhwB",
        "outputId": "5f31c899-094f-4031-dcfa-c6fb042b5253"
      },
      "source": [
        "# Fit the model to the 10% training data subsets\n",
        "model_7_history = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder_10_percent\")])"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent/20211029-101545\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 6s 136ms/step - loss: 0.6887 - accuracy: 0.5572 - val_loss: 0.6814 - val_accuracy: 0.6654\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.6763 - accuracy: 0.7004 - val_loss: 0.6697 - val_accuracy: 0.7362\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.6647 - accuracy: 0.7569 - val_loss: 0.6585 - val_accuracy: 0.7703\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 1s 46ms/step - loss: 0.6541 - accuracy: 0.7792 - val_loss: 0.6478 - val_accuracy: 0.7822\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.6436 - accuracy: 0.7806 - val_loss: 0.6377 - val_accuracy: 0.7861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAizuJ8EWhtt",
        "outputId": "0273051a-434a-4f22-e82d-c172c97678f3"
      },
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.48837954],\n",
              "       [0.519902  ],\n",
              "       [0.5993718 ],\n",
              "       [0.45714843],\n",
              "       [0.5425204 ],\n",
              "       [0.5635559 ],\n",
              "       [0.5653587 ],\n",
              "       [0.5866082 ],\n",
              "       [0.55656636],\n",
              "       [0.4318048 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u5ZTN63WhrY",
        "outputId": "f96c11be-df7e-4ea2-842b-7ccf7536afd7"
      },
      "source": [
        "# Turn pred probs into labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Nd-VBJUTEP6",
        "outputId": "9f6e4360-c1f6-41ba-c052-ccaf17961b10"
      },
      "source": [
        "# Evaluate model 7 predictions\n",
        "model_7_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_7_preds)\n",
        "model_7_results"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.60892388451444,\n",
              " 'f1': 0.7861133605334909,\n",
              " 'precision': 0.7861401983097992,\n",
              " 'recall': 0.7860892388451444}"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsmTu3oDaZvO",
        "outputId": "4667cfbb-f5e3-46bf-fad9-ce100f5642c3"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxTi4CGhaZqV"
      },
      "source": [
        ""
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaiI9S25aZni"
      },
      "source": [
        "## Comparing the performance of each of our models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQrwJhoqaZMg"
      },
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"0_baseline\": baseline_results,\n",
        "                                  \"1_simple_dense\": model_1_results,\n",
        "                                  \"2_lstm\": model_2_results,\n",
        "                                  \"3_gru\": model_3_results,\n",
        "                                  \"4_bidirectional\": model_4_results,\n",
        "                                  \"5_conv1d\": model_5_results,\n",
        "                                  \"6_tf_hub_use_encoder\": model_6_results,\n",
        "                                  \"7_tf_hub_use_encoder_10_percent\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "HJJSUUuOaZH3",
        "outputId": "ddef8ea9-cb45-4347-fcca-6e4d42ddbbe3"
      },
      "source": [
        "# Reduce the accuracy to the same scale as the other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"] / 100\n",
        "all_model_results"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>0.786089</td>\n",
              "      <td>0.789207</td>\n",
              "      <td>0.786089</td>\n",
              "      <td>0.783708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm</th>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.785439</td>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.775957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_gru</th>\n",
              "      <td>0.774278</td>\n",
              "      <td>0.775738</td>\n",
              "      <td>0.774278</td>\n",
              "      <td>0.772357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.767059</td>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.764784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.750183</td>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.750086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_use_encoder</th>\n",
              "      <td>0.790026</td>\n",
              "      <td>0.790927</td>\n",
              "      <td>0.790026</td>\n",
              "      <td>0.788674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.791492</td>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.784697</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 accuracy  precision    recall        f1\n",
              "0_baseline                       0.792651   0.811139  0.792651  0.786219\n",
              "1_simple_dense                   0.786089   0.789207  0.786089  0.783708\n",
              "2_lstm                           0.779528   0.785439  0.779528  0.775957\n",
              "3_gru                            0.774278   0.775738  0.774278  0.772357\n",
              "4_bidirectional                  0.766404   0.767059  0.766404  0.764784\n",
              "5_conv1d                         0.750656   0.750183  0.750656  0.750086\n",
              "6_tf_hub_use_encoder             0.790026   0.790927  0.790026  0.788674\n",
              "7_tf_hub_use_encoder_10_percent  0.787402   0.791492  0.787402  0.784697"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "eyRvkCfwaZEH",
        "outputId": "fa205b77-41db-43ba-d981-778c0ee5ad7c"
      },
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind='bar', figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "XqXgMBqdaY9t",
        "outputId": "69b0b726-ae80-46f4-901f-4aad778825fd"
      },
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7))"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f02be167f90>"
            ]
          },
          "metadata": {},
          "execution_count": 158
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHfOfR-AaY7V"
      },
      "source": [
        "## Uploading our model training logs to TensorBoard.dev\n",
        "We can further inspect our model's performance using TensorBoard.dev: https://tensorboard.dev/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3toMdRxXaY4A",
        "outputId": "84b7e1e5-60c4-452b-a5f4-c27923c2d008"
      },
      "source": [
        "# View TensorBoard logs of transfer learning modelling experiments (plus all of our other models)\n",
        "# Upload TensorBoard dev records\n",
        "!tensorboard dev upload --logdir ./model_logs/ \\\n",
        "  --name \"NLP Modelling Experiments\" \\\n",
        "  --description \"Compareing multiple different types of model architectures on the Kaggle Tweets text classification dataset\" \\\n",
        "  --one_shot # exit the uploaded once uploading is finished"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-29 11:40:15.363496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-29 11:40:15.371923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-29 11:40:15.372538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/Tgvoz6A2SqesEb8i2AcxLQ/\n",
            "\n",
            "\u001b[1m[2021-10-29T11:40:15]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2021-10-29T11:40:24]\u001b[0m Total uploaded: 270 scalars, 0 tensors, 9 binary objects (4.9 MB)\n",
            "\u001b[1m[2021-10-29T11:40:24]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/Tgvoz6A2SqesEb8i2AcxLQ/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYgDTekeaYk8"
      },
      "source": [
        "Now I've ran the cell above, my modelling experiments are visible on TensorBoard.dev: https://tensorboard.dev/experiment/C6BcyKuvSKqi2ppQkf09vw/#scalars\n",
        "\n",
        "> **Resource:** TensorBoard is great for quickly tracking experiments but for larger scale experiments and a whole bunch more tracking options, check out Weights & Biases: https://wandb.ai/site"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJwe3ByR6ndw",
        "outputId": "bcac1ecc-a5aa-41af-e43c-d9160241ec8e"
      },
      "source": [
        "# # See the previous TensorBoard Dev experiments you've run...\n",
        "# !tensorboard dev list"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-29 11:58:40.823828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-29 11:58:40.833069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-10-29 11:58:40.833724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "https://tensorboard.dev/experiment/Tgvoz6A2SqesEb8i2AcxLQ/\n",
            "\tName                 NLP Modelling Experiments\n",
            "\tDescription          Compareing multiple different types of model architectures on the Kaggle Tweets text classification dataset\n",
            "\tId                   Tgvoz6A2SqesEb8i2AcxLQ\n",
            "\tCreated              2021-10-29 11:40:15 (18 minutes ago)\n",
            "\tUpdated              2021-10-29 11:40:24 (18 minutes ago)\n",
            "\tRuns                 18\n",
            "\tTags                 5\n",
            "\tScalars              270\n",
            "\tTensor bytes         0\n",
            "\tBinary object bytes  5148689\n",
            "https://tensorboard.dev/experiment/C6BcyKuvSKqi2ppQkf09vw/\n",
            "\tName                 NLP Modelling Experiments\n",
            "\tDescription          Compareing multiple different types of model architectures on the Kaggle Tweets text classification dataset\n",
            "\tId                   C6BcyKuvSKqi2ppQkf09vw\n",
            "\tCreated              2021-10-29 11:39:33 (19 minutes ago)\n",
            "\tUpdated              2021-10-29 11:39:42 (19 minutes ago)\n",
            "\tRuns                 18\n",
            "\tTags                 5\n",
            "\tScalars              270\n",
            "\tTensor bytes         0\n",
            "\tBinary object bytes  5148689\n",
            "https://tensorboard.dev/experiment/7SXld3YBTxuGOXw6vjOiXw/\n",
            "\tName                 [No Name]\n",
            "\tDescription          [No Description]\n",
            "\tId                   7SXld3YBTxuGOXw6vjOiXw\n",
            "\tCreated              2021-10-29 11:35:51 (22 minutes ago)\n",
            "\tUpdated              2021-10-29 11:35:59 (22 minutes ago)\n",
            "\tRuns                 18\n",
            "\tTags                 5\n",
            "\tScalars              270\n",
            "\tTensor bytes         0\n",
            "\tBinary object bytes  5148689\n",
            "Total: 3 experiment(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmGI5aKZaYia"
      },
      "source": [
        "# If you need to delete an experiment from TensorBoard, you can run the following:\n",
        "# !tensorboard dev delete --experiment_id 7SXld3YBTxuGOXw6vjOiXw"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p89nG_dKaYf0"
      },
      "source": [
        "## Saving and loading a trained model\n",
        "\n",
        "There are two main formats to save a model to in TensorFlow:\n",
        "1. The HDF5 format\n",
        "2. The `SavedModel` format (this is the default when using TensorFlow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk_TpG-_aX3y"
      },
      "source": [
        "# Save TF Hub Sentence Encoder model to HDF5 format\n",
        "model_6.save(\"model_6.h5\")"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzowOyU8aX1U"
      },
      "source": [
        "# Load model with custom Hub Layer (required HDF5 format)\n",
        "import tensorflow_hub as hub\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\",\n",
        "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzk8cwweaXz3",
        "outputId": "57419796-8c28-47eb-9c57-a73dff724d1f"
      },
      "source": [
        "# How does our loaded model perform?\n",
        "loaded_model_6.evaluate(val_sentences,\n",
        "                        val_labels)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 18ms/step - loss: 0.4956 - accuracy: 0.7900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.49556785821914673, 0.7900262475013733]"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5A9PIWjaXyD",
        "outputId": "8be8ef4f-15b0-4bab-db61-f18ac230f300"
      },
      "source": [
        "model_6_results"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.00262467191601,\n",
              " 'f1': 0.7886741430048517,\n",
              " 'precision': 0.7909267110841915,\n",
              " 'recall': 0.7900262467191601}"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTrF9CmUaXub"
      },
      "source": [
        "Now let's save to the `SavedModel` format...(see more on this here: https://www.tensorflow.org/tutorials/keras/save_and_load)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPyHuet7aXrO",
        "outputId": "2ca0b824-5317-4d13-f0f2-2c80462f8876"
      },
      "source": [
        "# Save TF Hub Sentence Encoder model to SavedModel format (default)\n",
        "model_6.save(\"model_6_SavedModel_format\")"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVlSfhYwaXo-"
      },
      "source": [
        "# Load in a model from the SavedModel format\n",
        "loaded_model_6_SavedModel_format = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nIoB0woaXmb",
        "outputId": "ee7cba54-c5cf-49c3-dc75-e250abfb7aef"
      },
      "source": [
        "# Evaluate model in SavedModel format\n",
        "loaded_model_6_SavedModel_format.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 18ms/step - loss: 0.4956 - accuracy: 0.7900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.49556785821914673, 0.7900262475013733]"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybRUFigqaXhi"
      },
      "source": [
        "## Finding the most wrong examples\n",
        "\n",
        "* If our best model still isn't perfect, what examples is it getting wrong?\n",
        "* And of these wrong examples which ones is it getting *most* wrong (those with prediction probabilities closes to the opposite class)\n",
        "\n",
        "For example if a sample should have a label of 0 but our model predicts a prediction probability of 0.999 (really close to 1) and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn3uJj_CANbp",
        "outputId": "c1d39ae2-0ab6-4c59-f94e-e0e64b3a1b12"
      },
      "source": [
        "# Download a pretrained model from Google Storage\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
        "!unzip 08_model_6_USE_feature_extractor.zip"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-29 12:24:14--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.152.128, 74.125.124.128, 172.217.212.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.152.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960779165 (916M) [application/zip]\n",
            "Saving to: ‘08_model_6_USE_feature_extractor.zip’\n",
            "\n",
            "08_model_6_USE_feat 100%[===================>] 916.27M   103MB/s    in 13s     \n",
            "\n",
            "2021-10-29 12:24:27 (70.1 MB/s) - ‘08_model_6_USE_feature_extractor.zip’ saved [960779165/960779165]\n",
            "\n",
            "Archive:  08_model_6_USE_feature_extractor.zip\n",
            "   creating: 08_model_6_USE_feature_extractor/\n",
            "   creating: 08_model_6_USE_feature_extractor/assets/\n",
            "   creating: 08_model_6_USE_feature_extractor/variables/\n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
            "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZMdSBM4A05t",
        "outputId": "97d6a9c8-17f1-4fa1-bb17-98c2d79bfaa3"
      },
      "source": [
        "# Import previously trained model from Google Storage\n",
        "model_6_pretrained = tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")\n",
        "model_6_pretrained.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 16ms/step - loss: 0.4272 - accuracy: 0.8163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42723122239112854, 0.8162729740142822]"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIzflWhABCWl",
        "outputId": "51bc7ef3-996f-48d3-a52f-651e6bdad053"
      },
      "source": [
        "# Make predictions with the loaded model from GS\n",
        "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
        "model_6_pretrained_preds[:10] # these should be in label format"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW7avcFJC9hz",
        "outputId": "a9ee29b7-24b9-4ae0-c6a4-19d1c92787c6"
      },
      "source": [
        "model_6_pretrained_pred_probs.shape"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "GzRT5WbraXez",
        "outputId": "2d206aac-d82e-4272-bb8d-4a4032106ccd"
      },
      "source": [
        "# Create DataFrame with validation sentences, validation labels and best performing model predictions plus probabilities\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_pretrained_preds,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pretrained_pred_probs)})\n",
        "val_df.head()\n",
        "\n"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.747162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.707808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.159757\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.747162\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988749\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.196229\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.707808"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "rb_6GWnOaXca",
        "outputId": "adc0f637-cbb3-4bf3-ab02-5ff77c540d80"
      },
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
        "most_wrong[:10]"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.876982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.835454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.814816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.810840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.803122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>@freefromwolves GodsLove &amp;amp; #thankU brother...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>Air Group is here to the rescue! We have 24/7 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   0.910196\n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   0.876982\n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   0.852300\n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   0.835454\n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   0.827213\n",
              "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   0.814816\n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   0.810840\n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   0.803122\n",
              "119  @freefromwolves GodsLove &amp; #thankU brother...       0   1.0   0.766901\n",
              "344  Air Group is here to the rescue! We have 24/7 ...       0   1.0   0.766625"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "dTy5PLs1DqsL",
        "outputId": "84b58922-f5f9-40ff-b8a0-6f9603586bac"
      },
      "source": [
        "most_wrong.tail()"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>I get to smoke my shit in peace</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Why are you deluged with low self-image? Take ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   0.043919\n",
              "233                    I get to smoke my shit in peace       1   0.0   0.042087\n",
              "38   Why are you deluged with low self-image? Take ...       1   0.0   0.038998\n",
              "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   0.038949\n",
              "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   0.037186"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTGD6GcBDh72"
      },
      "source": [
        "Let's remind ourselves of the target labels...\n",
        "* `0` = not disaster\n",
        "* `1` = disaster"
      ]
    }
  ]
}